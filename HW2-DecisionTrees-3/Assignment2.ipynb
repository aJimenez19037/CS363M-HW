{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This assignment may be worked individually or in pairs. Enter your name/s here:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Alexa Aguilar Izquierdo\n",
    "# Antonio Oldair Jimenez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Assignment 2: Decision Trees\n",
    "\n",
    "In this assignment we'll implement the Decision Tree algorithm to classify patients as either having or not having diabetic retinopathy. For this task we'll be using the Diabetic Retinopathy data set, which contains features from the Messidor image set to predict whether an image contains signs of diabetic retinopathy or not. This dataset has `1150` instances and `20` attributes (some categorical, some continuous). You can find additional details about the dataset [here](http://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "    0) The binary result of quality assessment. 0=bad quality 1=sufficient quality.\n",
    "\n",
    "    1) The binary result of pre-screening, where 1 indicates severe retinal abnormality and 0 its lack. \n",
    "\n",
    "    2-7) The results of MA detection. Each feature value stand for the number of MAs found at the confidence levels alpha = 0.5, . . . , 1, respectively. \n",
    "\n",
    "    8-15) Contains the same information as 2-7, but for exudates. However, as exudates are represented by a set of points rather than the number of pixels constructing the lesions, these features are normalized by dividing the number of lesions with the diameter of the region of interest (ROI) to compensate for different image sizes. \n",
    "\n",
    "    16) The euclidean distance between the center of the macula and the center of the optic disc. This feature is also normalized with the diameter of the ROI.\n",
    "\n",
    "    17) The diameter of the optic disc. \n",
    "\n",
    "    18) Result of the AM/FM-based (amplitude-modulation frequency-modulation) imaging. 0=normal and 1=abnormal.\n",
    "\n",
    "    19) Class label. 1 = contains signs of Diabetic Retinopathy, 0 = no signs of Diabetic Retinopathy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation: \n",
    "The function prototypes are given to you, please don't change these. You can add additional helper functions if needed. \n",
    "\n",
    "*Suggestion:* The dataset is substantially big, for the purpose of easy debugging, work with a subset of the data and test your decision tree implementation on that.\n",
    "\n",
    "#### Notes:\n",
    "Parts of this assignment will be **autograded** so a couple of caveats :-\n",
    "- Entropy is calculated using log with base 2, `math.log2(x)`.\n",
    "- For continuous features ensure that the threshold value lies exactly between 2 values. For example, if for feature 2 the best split occurs between 10 and 15 then the threshold value will be set as 12.5. For binary features [0/1] the threshold value will be 0.5.\n",
    "- All values < `thresh_val` go to the left child and all values >= `thresh_val` go to the right child."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Standard Headers\n",
    "# You are welcome to add additional headers if you wish\n",
    "# EXCEPT for scikit-learn... You may NOT use scikit-learn for this assignment!\n",
    "import pandas as pd\n",
    "from math import log2\n",
    "import time\n",
    "from numpy import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    is_leaf = True          # boolean variable to check if the node is a leaf\n",
    "    feature_idx = None      # index that identifies the feature\n",
    "    thresh_val = None       # threshold value that splits the node\n",
    "    prediction = None       # prediction class (only valid for leaf nodes)\n",
    "    left_child = None       # left TreeNode (all values < thresh_val)\n",
    "    right_child = None      # right TreeNode (all values >= thresh_val)\n",
    "    \n",
    "    def printTree(self, level=0):    # for debugging purposes\n",
    "        if self.is_leaf:\n",
    "            print ('-'*level + 'Leaf Node:      predicts ' + str(self.prediction))\n",
    "        else:\n",
    "            print ('-'*level + 'Internal Node:  splits on feature ' \n",
    "                   + str(self.feature_idx) + ' with threshold ' + str(self.thresh_val))\n",
    "            self.left_child.printTree(level+1)\n",
    "            self.right_child.printTree(level+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Implement the function `make_prediction` that takes the decision tree root and a data point instance and returns the prediction label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_prediction(tree_root, data_point):\n",
    "    if tree_root.is_leaf:\n",
    "        return tree_root.prediction\n",
    "    else:\n",
    "        feature = tree_root.feature_idx\n",
    "        if data_point.iloc[feature] < tree_root.thresh_val:\n",
    "            make_prediction(tree_root.left_child, data_point)\n",
    "        else:\n",
    "            make_prediction(tree_root.right_child, data_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Implement the function `split_dataset` given an input data set, a `feature_idx` and the `threshold` for the feature. `left_split` will have all values < `threshold` and `right_split` will have all values >= `threshold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(data, feature_idx, threshold):\n",
    "    left_split = data[data.iloc[:,feature_idx] < threshold]\n",
    "    right_split = data[data.iloc[:,feature_idx] >= threshold]\n",
    "    return (left_split, right_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Implement the function `calc_entropy` to return the entropy of the input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_entropy(data) -> float:\n",
    "    entropy = 0.0\n",
    "    #your code goes here\n",
    "    left, right = split_dataset(data, -1, 0.5)\n",
    "\n",
    "    if len(left) == 0 or len(right) == 0:\n",
    "        return entropy\n",
    "\n",
    "    def sub_entropy(sub):\n",
    "        return -1 * (len(sub) / len(data)) * (log2((len(sub)) / len(data)))\n",
    "        \n",
    "    entropy = sub_entropy(left) + sub_entropy(right)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Implement the function `calc_best_threshold` which returns the best information gain and the corresponding threshold value for one feature at `feature_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_best_threshold(data, feature_idx):\n",
    "    best_info_gain = 0.0\n",
    "    best_thresh = None\n",
    "    #your code goes here\n",
    " \n",
    "    data = data.sort_values(by=feature_idx)\n",
    "    data = data.reset_index(drop=True)\n",
    " \n",
    "    previous = None\n",
    " \n",
    "    def info_gain(threshold):\n",
    "        # entropy parent - sum of entropy child nodes\n",
    "        left, right = split_dataset(data, feature_idx, threshold)\n",
    "        entropy_left = calc_entropy(left) * (len(left)/len(data))\n",
    "        entropy_right = calc_entropy(right) * (len(right)/len(data))\n",
    "        return calc_entropy(data) - entropy_left - entropy_right\n",
    "   \n",
    "    for i, value in enumerate(data.iloc[:, -1]):\n",
    "        if i == 0: # skip checking threhold of 0 and -1\n",
    "            previous = value\n",
    "            continue\n",
    "        if value == previous: # no threshold\n",
    "            continue\n",
    "        else: # threshold\n",
    "            threshold = (data.iloc[i, feature_idx] + data.iloc[i-1, feature_idx]) / 2\n",
    "            info_gain_threshold = info_gain(threshold)\n",
    "            if info_gain_threshold > best_info_gain:\n",
    "                best_info_gain = info_gain_threshold\n",
    "                best_thresh = threshold    \n",
    "        previous = value\n",
    "    return (best_info_gain, best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Implement the function `identify_best_split` which returns the best feature to split on for an input dataset, and also returns the corresponding threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def identify_best_split(data):\n",
    "    if len(data) < 2:\n",
    "        return (None, None)\n",
    "        \n",
    "    best_feature = None\n",
    "    best_thresh = None\n",
    "    best_info_gain, best_thresh = calc_best_threshold(data, 0)\n",
    "    #your code goes here\n",
    "    for feature_idx in range(len(data.columns) - 1):\n",
    "        if feature_idx == 0:\n",
    "            best_feature = 0\n",
    "        else:\n",
    "            info_gain, thresh = calc_best_threshold(data, feature_idx)\n",
    "            if info_gain > best_info_gain:\n",
    "                best_info_gain = info_gain\n",
    "                best_feature = feature_idx\n",
    "                best_thresh = thresh\n",
    "   \n",
    "    return (best_feature, best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Implement the function `create_leaf_node` which returns a `TreeNode` with `is_leaf=True` and `prediction` set to whichever classification occurs most in the dataset at this node. If there is a tie, choose classification label 1 (has disease). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_leaf_node(data):        \n",
    "    #your code goes here\n",
    "    # is_leaf = True          # boolean variable to check if the node is a leaf\n",
    "    # feature_idx = None      # index that identifies the feature\n",
    "    # thresh_val = None       # threshold value that splits the node\n",
    "    # prediction = None       # prediction class (only valid for leaf nodes)\n",
    "    # left_child = None       # left TreeNode (all values < thresh_val)\n",
    "    # right_child = None      # right TreeNode (all values >= thresh_val)\n",
    "\n",
    "    leaf_node = TreeNode()\n",
    "    leaf_node.is_leaf = True\n",
    "    no_disease = len(data[data.iloc[:, -1] == 0])    \n",
    "    disease = len(data[data.iloc[:, -1] == 1])\n",
    "    if no_disease > disease:\n",
    "        leaf_node.prediction = 0\n",
    "    elif disease > no_disease:\n",
    "        leaf_node.prediction = 1\n",
    "    else:\n",
    "        leaf_node.prediction = 1\n",
    "    return leaf_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Implement the `create_decision_tree` function. `max_levels` denotes the maximum height of the tree - For example, if `max_levels = 1` then the decision tree will only contain the leaf node at the root. [Hint: this is where the recursion happens.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_decision_tree(data, max_levels):\n",
    "\n",
    "    def recursive_tree(data, i):\n",
    "        if data is not None:\n",
    "            best_feature, best_thresh = identify_best_split(data)\n",
    "            \n",
    "            if i == max_levels or best_thresh is None:\n",
    "                return create_leaf_node(data)\n",
    "            else:\n",
    "                left, right = split_dataset(data, best_feature, best_thresh)\n",
    "                node = TreeNode()\n",
    "                node.is_leaf = False\n",
    "                node.feature_idx = best_feature\n",
    "                node.thresh_val = best_thresh\n",
    "                \n",
    "                node.right_child = recursive_tree(right, i+1)\n",
    "                node.left_child = recursive_tree(left, i+1)\n",
    "                return node\n",
    "        else:\n",
    "            return \n",
    " \n",
    "    root = recursive_tree(data, 1)\n",
    "\n",
    "    return root\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. Given a decision tree and a test set, the function `calc_accuracy` returns the accuracy of the classifier. You'll use the `make_prediction` function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(tree_root, test_data):\n",
    "    modified_data = test_data.drop(test_data.columns[-1], axis=1)\n",
    "    correct = 0\n",
    "   \n",
    "    for i in range(modified_data.shape[0]):\n",
    "        prediction = make_prediction(tree_root, modified_data.iloc[i, :])\n",
    "        print(prediction, test_data.iloc[i, -1])\n",
    "        if prediction == test_data.iloc[i, -1]:\n",
    "            correct += 1\n",
    "           \n",
    "    return correct/modified_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. Now measure the accuracy of using a decision tree on this data with a 5-fold cross validation. \n",
    "Set the `max_levels` parameter to 10 and print the accuracy from a 5-fold-CV.\n",
    "\n",
    "This must run in under 10 minutes, otherwise points will be deducted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Node:  splits on feature 14 with threshold 0.059243000000000004\n",
      "-Internal Node:  splits on feature 2 with threshold 69.0\n",
      "--Internal Node:  splits on feature 8 with threshold 147.875086\n",
      "---Internal Node:  splits on feature 8 with threshold 30.0813355\n",
      "----Internal Node:  splits on feature 17 with threshold 0.0866005\n",
      "-----Leaf Node:      predicts 1\n",
      "-----Internal Node:  splits on feature 2 with threshold 55.5\n",
      "------Internal Node:  splits on feature 8 with threshold 29.553185499999998\n",
      "-------Internal Node:  splits on feature 11 with threshold 0.10185649999999999\n",
      "--------Internal Node:  splits on feature 8 with threshold 27.3275705\n",
      "---------Leaf Node:      predicts 0\n",
      "---------Leaf Node:      predicts 0\n",
      "--------Internal Node:  splits on feature 8 with threshold 11.194698500000001\n",
      "---------Leaf Node:      predicts 1\n",
      "---------Leaf Node:      predicts 0\n",
      "-------Leaf Node:      predicts 1\n",
      "------Internal Node:  splits on feature 5 with threshold 57.0\n",
      "-------Internal Node:  splits on feature 17 with threshold 0.1356985\n",
      "--------Leaf Node:      predicts 1\n",
      "--------Internal Node:  splits on feature 2 with threshold 58.5\n",
      "---------Leaf Node:      predicts 0\n",
      "---------Leaf Node:      predicts 1\n",
      "-------Internal Node:  splits on feature 7 with threshold 40.5\n",
      "--------Leaf Node:      predicts 0\n",
      "--------Internal Node:  splits on feature 11 with threshold 0.0585405\n",
      "---------Leaf Node:      predicts 0\n",
      "---------Leaf Node:      predicts 1\n",
      "----Internal Node:  splits on feature 2 with threshold 15.5\n",
      "-----Internal Node:  splits on feature 8 with threshold 105.2564065\n",
      "------Internal Node:  splits on feature 5 with threshold 12.5\n",
      "-------Internal Node:  splits on feature 18 with threshold 0.5\n",
      "--------Internal Node:  splits on feature 9 with threshold 21.472825\n",
      "---------Leaf Node:      predicts 0\n",
      "---------Leaf Node:      predicts 1\n",
      "--------Internal Node:  splits on feature 13 with threshold 0.0009989999999999999\n",
      "---------Leaf Node:      predicts 0\n",
      "---------Leaf Node:      predicts 0\n",
      "-------Leaf Node:      predicts 0\n",
      "------Leaf Node:      predicts 0\n",
      "-----Internal Node:  splits on feature 6 with threshold 32.0\n",
      "------Internal Node:  splits on feature 2 with threshold 38.0\n",
      "-------Internal Node:  splits on feature 15 with threshold 0.000481\n",
      "--------Internal Node:  splits on feature 6 with threshold 11.0\n",
      "---------Leaf Node:      predicts 1\n",
      "---------Leaf Node:      predicts 1\n",
      "--------Internal Node:  splits on feature 10 with threshold 3.9197245\n",
      "---------Leaf Node:      predicts 0\n",
      "---------Leaf Node:      predicts 0\n",
      "-------Leaf Node:      predicts 1\n",
      "------Internal Node:  splits on feature 17 with threshold 0.083457\n",
      "-------Leaf Node:      predicts 1\n",
      "-------Internal Node:  splits on feature 11 with threshold 4.15723\n",
      "--------Internal Node:  splits on feature 8 with threshold 112.0717925\n",
      "---------Leaf Node:      predicts 0\n",
      "---------Leaf Node:      predicts 1\n",
      "--------Leaf Node:      predicts 0\n",
      "---Internal Node:  splits on feature 3 with threshold 4.5\n",
      "----Leaf Node:      predicts 0\n",
      "----Internal Node:  splits on feature 11 with threshold 2.097043\n",
      "-----Internal Node:  splits on feature 16 with threshold 0.5746795\n",
      "------Leaf Node:      predicts 1\n",
      "------Leaf Node:      predicts 0\n",
      "-----Internal Node:  splits on feature 2 with threshold 25.5\n",
      "------Internal Node:  splits on feature 10 with threshold 24.705830499999998\n",
      "-------Internal Node:  splits on feature 9 with threshold 32.603088\n",
      "--------Internal Node:  splits on feature 5 with threshold 18.5\n",
      "---------Leaf Node:      predicts 1\n",
      "---------Leaf Node:      predicts 0\n",
      "--------Leaf Node:      predicts 0\n",
      "-------Internal Node:  splits on feature 9 with threshold 75.1398305\n",
      "--------Leaf Node:      predicts 1\n",
      "--------Internal Node:  splits on feature 9 with threshold 85.4423505\n",
      "---------Leaf Node:      predicts 0\n",
      "---------Leaf Node:      predicts 1\n",
      "------Internal Node:  splits on feature 9 with threshold 160.56887899999998\n",
      "-------Internal Node:  splits on feature 13 with threshold 0.1175535\n",
      "--------Leaf Node:      predicts 1\n",
      "--------Leaf Node:      predicts 0\n",
      "-------Leaf Node:      predicts 0\n",
      "--Internal Node:  splits on feature 7 with threshold 41.0\n",
      "---Leaf Node:      predicts 1\n",
      "---Internal Node:  splits on feature 9 with threshold 9.467481\n",
      "----Internal Node:  splits on feature 7 with threshold 65.0\n",
      "-----Leaf Node:      predicts 1\n",
      "-----Internal Node:  splits on feature 1 with threshold 0.5\n",
      "------Leaf Node:      predicts 0\n",
      "------Leaf Node:      predicts 1\n",
      "----Internal Node:  splits on feature 14 with threshold 0.0023375\n",
      "-----Internal Node:  splits on feature 16 with threshold 0.504502\n",
      "------Leaf Node:      predicts 0\n",
      "------Internal Node:  splits on feature 16 with threshold 0.5501275\n",
      "-------Internal Node:  splits on feature 9 with threshold 11.8138695\n",
      "--------Internal Node:  splits on feature 8 with threshold 24.9559745\n",
      "---------Leaf Node:      predicts 1\n",
      "---------Leaf Node:      predicts 0\n",
      "--------Leaf Node:      predicts 1\n",
      "-------Internal Node:  splits on feature 7 with threshold 43.5\n",
      "--------Leaf Node:      predicts 1\n",
      "--------Leaf Node:      predicts 0\n",
      "-----Leaf Node:      predicts 1\n",
      "-Internal Node:  splits on feature 15 with threshold 0.1899705\n",
      "--Internal Node:  splits on feature 8 with threshold 103.87292500000001\n",
      "---Internal Node:  splits on feature 9 with threshold 29.327102500000002\n",
      "----Internal Node:  splits on feature 12 with threshold 0.467473\n",
      "-----Internal Node:  splits on feature 11 with threshold 0.5357179999999999\n",
      "------Leaf Node:      predicts 1\n",
      "------Internal Node:  splits on feature 7 with threshold 28.0\n",
      "-------Internal Node:  splits on feature 2 with threshold 30.5\n",
      "--------Leaf Node:      predicts 0\n",
      "--------Leaf Node:      predicts 1\n",
      "-------Leaf Node:      predicts 0\n",
      "-----Leaf Node:      predicts 1\n",
      "----Internal Node:  splits on feature 12 with threshold 1.5328985\n",
      "-----Internal Node:  splits on feature 5 with threshold 23.0\n",
      "------Leaf Node:      predicts 0\n",
      "------Leaf Node:      predicts 1\n",
      "-----Leaf Node:      predicts 0\n",
      "---Leaf Node:      predicts 1\n",
      "--Leaf Node:      predicts 1\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n",
      "None 1\n",
      "None 0\n",
      "None 1\n"
     ]
    }
   ],
   "source": [
    "def run_CV(filename):\n",
    "    start = time.time()\n",
    "    \n",
    "    # read in data\n",
    "    d = pd.read_csv(filename, header = None)\n",
    "\n",
    "    #your code goes here\n",
    "    chunk_size = int(d.shape[0] / 5)\n",
    "    accuracies = []\n",
    "    for start in range(0, d.shape[0], chunk_size):\n",
    "        d_validate = d.iloc[start:start + chunk_size] # extract chunk for testing\n",
    "        # calculate accuracy\n",
    "        d_temp = d.drop(d_validate.index)\n",
    "        tree_root = create_decision_tree(d_temp, 10)\n",
    "        tree_root.printTree()\n",
    "        accuracies.append(calc_accuracy(tree_root, d_validate))\n",
    "\n",
    "    five_fold_accruacy = mean(accuracies)\n",
    "    print(five_fold_accruacy)\n",
    "    end = time.time()\n",
    "    print ('Time taken:', end - start)\n",
    "\n",
    "\n",
    "run_CV(\"messidor_features.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
